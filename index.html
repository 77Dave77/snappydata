<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="Project documentation for SnappyData">
  <meta name="author" content="SnappyData Team">
  
  <title>SnappyData Documentation</title>
  

  <link rel="shortcut icon" href="favicon.ico">
  

  
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="./css/theme.css" type="text/css" />
  <link rel="stylesheet" href="./css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="./css/highlight.css">
  <link href="./extra.css" rel="stylesheet">

  
  <script>
    // Current page data
    var mkdocs_page_name = "None";
    var mkdocs_page_input_path = "index.md";
    var mkdocs_page_url = "/";
  </script>
  
  <script src="./js/jquery-2.1.1.min.js"></script>
  <script src="./js/modernizr-2.8.3.min.js"></script>
  <script type="text/javascript" src="./js/highlight.pack.js"></script>
  <script src="./js/theme.js"></script> 

  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href="." class="icon icon-home"> SnappyData Documentation</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="./search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        <ul class="current">
          
            <li>
    <li class="toctree-l1 current">
        <a class="current" href=".">Overview</a>
        
            <ul>
            
                <li class="toctree-l3"><a href="#introduction">Introduction</a></li>
                
                    <li><a class="toctree-l4" href="#the-challenge-with-spark-and-remote-data-sources">The Challenge with Spark and Remote Data Sources</a></li>
                
                    <li><a class="toctree-l4" href="#the-snappydata-approach">The SnappyData Approach</a></li>
                
            
                <li class="toctree-l3"><a href="#key-features">Key Features</a></li>
                
            
                <li class="toctree-l3"><a href="#extensions-to-the-spark-runtime">Extensions to the Spark Runtime</a></li>
                
            
                <li class="toctree-l3"><a href="#spark-challenges-for-mixed-workloads-oltp-olap">Spark Challenges for Mixed Workloads (OLTP, OLAP)</a></li>
                
            
            </ul>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="quickstart/">Getting Started</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="install/">Download and Install</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="howto/">How Tos</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="architecture/">Architecture</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="configuration/">Configuring the Cluster</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="programming_guide/">Programming Guide</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="deployment/">Affinity Modes</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="aqp/">Synopsis Data Engine (SDE)</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="aqp_aws/">Using iSight-Cloud</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="apidocsintro/">API</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="additional_docs/">Reference Documents</a>
        
    </li>
<li>
          
            <li>
    <ul class="subnav">
    <li><span>About</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="techsupport/">Contact and Support</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="LICENSE/">License</a>
        
    </li>

        
    </ul>
<li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href=".">SnappyData Documentation</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".">Docs</a> &raquo;</li>
    
      
    
    <li>Overview</li>
    <li class="wy-breadcrumbs-aside">
      
        
          <a href="https://github.com/SnappyDataInc/snappydata" class="icon icon-github"> Edit on GitHub</a>
        
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h2 id="introduction">Introduction</h2>
<p>SnappyData fuses Apache Spark with an in-memory database to deliver a data engine capable of processing streams, transactions and interactive analytics in a single cluster.</p>
<h3 id="the-challenge-with-spark-and-remote-data-sources">The Challenge with Spark and Remote Data Sources</h3>
<p>Apache Spark is a general purpose parallel computational engine for analytics at scale. At its core, it has a batch design center and can access disparate data sources in a highly parallelized manner for its distributed computations. Typically, data is fetched lazily as a result of SQL query or a Dataset (RDD) getting materialized. This can be quite inefficient and expensive if the data set has to be repeatedly processed. Caching within Spark is immutable and still requires the application to periodically refresh the data set, let alone having to bear the burden of duplicating the dataset. </p>
<p>Analytic processing requires massive data sets to be repeatedly copied and data to be reformatted to suit Spark. In many cases, it ultimately fails to deliver the promise of interactive analytic performance. For instance, each time an aggregation is run on a large Cassandra table, it necessitates streaming the entire table into Spark to do the aggregation. Caching within Spark is immutable and results in stale insight.</p>
<h3 id="the-snappydata-approach">The SnappyData Approach</h3>
<p>At SnappyData, we take a very different approach. SnappyData fuses a low latency, highly available in-memory transactional database (GemFireXD) into Spark with shared memory management and optimizations. Data in the highly available in-memory store is laid out using the same columnar format as Spark. All query engine operators are more optimized through better vectorization and code generation. The net effect is, an order of magnitude performance improvement when compared to native Spark caching, and more than two orders of magnitude better Spark performance when working with external data sources.</p>
<p>Essentially, we turn Spark into an in-memory operational database capable of transactions, point reads, writes, working with Streams (Spark) and running analytic SQL queries.</p>
<p><img alt="SnappyData Architecture" src="./Images/SnappyArchitecture.png" /></p>
<p>Conceptually, you can think of SnappyData as an <strong>in-memory database that uses Spark's API and SQL as its interface and computational engine</strong> - to process streams, work with myriad data sources like HDFS, and process data through a rich set of higher level abstractions. While the SnappyData engine is primarily designed for SQL processing, applications can work with Objects through Spark RDDs and the newly introduced Spark Datasets.</p>
<p>Any Spark DataFrame can be easily managed as a SnappyData Table or conversely any table can be accessed as a DataFrame.</p>
<p>By default, when the cluster is started, the data store is bootstrapped and when any Spark Jobs/OLAP queries are submitted, Spark executors are automatically launched within the SnappyData process space (JVMs). There is no need to connect and manage external data store clusters. The SnappyData store can synchronously replicate for high availability (HA) with strong consistency and store/recover from disk for additional reliability.</p>
<h2 id="key-features">Key Features</h2>
<ul>
<li>
<p><strong>100% compatible with Spark</strong> - Use SnappyData as a database, but also use any of the Spark APIs - ML, Graph, etc.</p>
</li>
<li>
<p><strong>In-memory row and column stores</strong>: Run the store collocated in Spark executors or in its own process space (i.e. a computational cluster and a data cluster)</p>
</li>
<li>
<p><strong>SQL standard compliance</strong>: Spark SQL + several SQL extensions: DML, DDL, indexing, constraints.</p>
</li>
<li>
<p><strong>SQL based extensions for streaming processing</strong>: Use native Spark streaming, DataFrame APIs or declaratively specify your streams and how you want it processed. You do not need to learn Spark APIs to get going with stream processing or its subtleties when processing in parallel.</p>
</li>
<li>
<p><strong>Not-Only SQL</strong>: Use either as a SQL database or work with JSON or even arbitrary Application Objects. Essentially, any Spark RDD/DataSet can also be persisted into SnappyData tables (type system same as Spark DataFrames). </p>
</li>
<li>
<p><strong>Interactive analytics using Synopsis Data Engine (SDE)</strong>: We introduce multiple synopses techniques through data structures like count-min-sketch and stratified sampling to dramatically reduce the in-memory space requirements and provide true interactive speeds for analytic queries. These structures can be created and managed by developers with little to no statistical background and can be completely transparent to the SQL developer running queries. Error estimators are also integrated with simple mechanisms to get to the errors through built-in SQL functions.</p>
</li>
<li>
<p><strong>Mutate, transact on data in Spark</strong>: You can use SQL to insert, update, delete data in tables as one would expect. We also provide extensions to Spark’s context so you can mutate data in your Spark programs. Any tables in SnappyData is visible as DataFrames without having to maintain multiples copies of your data: cached RDDs in Spark and then separately in your data store.</p>
</li>
<li>
<p><strong>Optimizations - Indexing</strong>: You can index your RowStore and the GemFire SQL optimizer, which automatically uses in-memory indexes when available.</p>
</li>
<li>
<p><strong>Optimizations - collocation</strong>: SnappyData implements several optimizations to improve data locality and avoid shuffling data for queries on partitioned data sets. All related data can be collocated using declarative custom partitioning strategies (for example, common shared business key). Reference data tables can be modeled as replicated tables when tables cannot share a common key. Replicas are always consistent.</p>
</li>
<li>
<p><strong>High availability not just Fault tolerance</strong>: Data can be instantly replicated (one at a time or batch at a time) to other nodes in the cluster. It is deeply integrated with a membership-based distributed system to detect and handle failures, instantaneously providing applications continuous HA.</p>
</li>
<li>
<p><strong>Durability and recovery:</strong> Data can also be managed on disk and automatically recovered. Utilities for backup and restore are bundled.</p>
</li>
</ul>
<p><a id="SparkChallenges"></a></p>
<h2 id="extensions-to-the-spark-runtime">Extensions to the Spark Runtime</h2>
<p>SnappyData makes the following contributions to deliver a unified and optimized runtime.</p>
<ul>
<li>
<p><strong>Integrating an operational in-memory data store with Spark’s computational model</strong>: We introduce a number of extensions to fuse our runtime with that of Spark. Spark executors run in the same process space as our store’s execution threads, sharing the same pool of memory. When Spark executes tasks in a partitioned manner, it is designed to keep all the available CPU cores busy. <br/> We extend this design by allowing low latency and fine- grained operations to interleave and get higher priority, without involving the scheduler. Furthermore, to support high concurrency, we extend the runtime with a “Job Server” that decouples applications from data servers, operating much in the same way as a traditional database, whereby the state is shared across many clients and applications. <br/></p>
</li>
<li>
<p><strong>Unified API for OLAP, OLTP, and Streaming</strong>: Spark builds on a common set of abstractions to provide a rich API for a diverse range of applications, such as MapReduce, Machine learning, stream processing, and SQL.
While Spark deserves much of the credit for being the first of its kind to offer a unified API, we further extend its API to: </p>
<ul>
<li>
<p>Allow for OLTP operations, for example, transactions and mutations (inserts/updates/deletions) on tables </p>
</li>
<li>
<p>Confirm with SQL standards, for example, allowing tables alterations, constraints, indexes, and   </p>
</li>
<li>
<p>Support declarative stream processing in SQL</p>
</li>
</ul>
</li>
<li>
<p><strong>Optimizing Spark application execution times</strong>: Our goal is to eliminate the need for yet another external store (for example, a KV store) for Spark applications. With a deeply integrated store, SnappyData improves overall performance by minimizing network traffic and serialization costs. In addition, by promoting collocated schema designs (tables and streams) where related data is collocated in the same process space, SnappyData eliminates the need for shuffling altogether in several scenarios.</p>
</li>
<li>
<p><strong>Synopsis Data Engine support built into Spark</strong>: The SnappyData Synopsis Data Engine (SDE) offers a novel and scalable system to analyze large data sets. SDE uses statistical sampling techniques and probabilistic data structures to answer analytic queries with sub-second latency. There is no need to store or process the entire data set. The approach trades off query accuracy for fast response time. <br>The SDE engine enables you to:</p>
<ul>
<li>
<p>Intelligently sample the data set on frequently accessed dimensions so we have a good representation across the entire data set (stratified sampling). Queries can execute on samples and return answers instantly.</p>
</li>
<li>
<p>Compute estimates for any ad hoc query from the sample(s). It can also provide error estimates for arbitrarily complex queries on streams.</p>
</li>
<li>
<p>Provide simple knobs for the user to trade off speed for accuracy, i.e. simple SQL extensions so the user can specify the error tolerance for all queries. When query error is higher than tolerance level, the system automatically delegates the query to the source.</p>
</li>
<li>
<p>Express their accuracy requirements as high-level accuracy contracts (HAC), without overwhelming them with numerous statistical concepts.</p>
</li>
</ul>
</li>
</ul>
<h2 id="spark-challenges-for-mixed-workloads-oltp-olap">Spark Challenges for Mixed Workloads (OLTP, OLAP)</h2>
<p>Spark is designed as a computational engine for processing batch jobs. Each Spark application (for example, a Map-reduce job) runs as an independent set of processes (i.e., executor JVMs) on the cluster. These JVMs are re- used for the lifetime of the application. While, data can be cached and reused in these JVMs for a single application, sharing data across applications or clients requires an external storage tier, such as HDFS. We, on the other hand, target a real-time, “always-on”, operational design center— clients can connect at will, and share data across any number of concurrent connections. This is similar to any operational database in the market today. Thus, to manage data in the same JVM, our first challenge is to alter the life cycle of these executors so that they are long-lived and decoupled from individual applications.</p>
<p>A second but related challenge is Spark’s design for how user requests (i.e., jobs) are handled. A single driver orchestrates all the work done on the executors. Given our need for high concurrency and a hybrid OLTP-OLAP workload, this driver introduces:</p>
<ol>
<li>
<p>A single point of contention for all requests, and </p>
</li>
<li>
<p>A barrier for achieving high availability (HA). Executors are shut down if the driver fails, requiring a full refresh of any cached state.</p>
</li>
</ol>
<p>Spark’s primary usage of memory is for caching RDDs and for shuffling blocks to other nodes. Data is managed in blocks and is immutable. On the other hand, we need to manage more complex data structures (along with indexes) for point access and updates. Therefore, another challenge is merging these two disparate storage systems with little impedance to the application. This challenge is exacerbated by current limitations of Spark SQL—mostly related to mutability characteristics and conformance to SQL.</p>
<p>Finally, Spark’s strong and growing community has zero tolerance for incompatible forks. This means that no changes can be made to Spark’s execution model or its semantics for existing APIs. In other words, our changes have to be an extension.</p>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="quickstart/" class="btn btn-neutral float-right" title="Getting Started">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
      <p>Copyright &copy; 2017 SnappyData Inc.</p>
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
	  
        </div>
      </div>

    </section>

  </div>

<div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
          <a href="https://github.com/SnappyDataInc/snappydata" class="icon icon-github" style="float: left; color: #fcfcfc"> GitHub</a>
      
      
      
        <span style="margin-left: 15px"><a href="quickstart/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>

</body>
</html>

<!--
MkDocs version : 0.15.3
Build Date UTC : 2017-03-10 20:37:20.149222
-->
